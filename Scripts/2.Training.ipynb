{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1X43cmBwfoUM-tjzQeFZj0JV4i7NuXkQR","timestamp":1669039563078},{"file_id":"1b795WMLLgDR25BkhJJQfe9T1AFM66U0c","timestamp":1667374129167},{"file_id":"1vyXZoZd_kOhxR-GWYoA-d0_GBkr8mwaM","timestamp":1663174240290},{"file_id":"1XlvuQdrqhn7GVhTsX73cw6NS3RiSb88F","timestamp":1648033815724},{"file_id":"1Cvzff4SEM7lXQ81RHq5Gky4e7nCCMQWO","timestamp":1644572144372},{"file_id":"1_Zf2Iq5Dn24nG_xBcUDZjqC_6lgn_dPI","timestamp":1643380183531},{"file_id":"1IO02kMGgzQPcH-pEUZMbQkqMot8kQrHa","timestamp":1643214785379},{"file_id":"1U-XWTDf51HxwU-999Hr7-suv2ZNZ9oDj","timestamp":1642080817920}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"_MJ4kW1pEhwP"},"source":["# Environment setup\n","\n"]},{"cell_type":"code","metadata":{"id":"neIa46CpciXq"},"source":["# Cloud authentication\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pscUeoicjVi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RnZzcYhcpsQ"},"source":["# Import modules\n","import tensorflow as tf\n","from tensorflow.keras.activations import softmax\n","import numpy as np\n","import os\n","from os import listdir\n","import datetime\n","import random\n","\n","%pip install git+https://github.com/artemmavrin/focal-loss.git --quiet\n","from focal_loss import SparseCategoricalFocalLoss\n","\n","%pip install rasterio --quiet\n","import rasterio\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score\n","\n","# Tensorflow version check\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set seed\n","def set_seed(seed: int = 42) -> None:\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  tf.random.set_seed(seed)\n","  tf.experimental.numpy.random.seed(seed)\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","set_seed()"],"metadata":{"id":"rSp7gBPJCqB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Base folder\n","base = '/content/drive/My Drive/Thesis2'"],"metadata":{"id":"EQ-cRNgtptHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define variables depending on the type of classes\n","\n","## Binary\n","# Nclasses = 3\n","# train_base = base + '/binary_train'\n","# val_base = base + '/binary_val'\n","# Weight=[0.0, 1.01, 0.99]\n","# model_dir = base + '/UNetBin'\n","# lbl = '/Data/TestBinLbl.tif'\n","# labels = ['Forest', 'Non forest']\n","\n","## Multi\n","Nclasses = 5\n","train_base = base + '/multi_train'\n","val_base = base + '/multi_val'\n","Weight=[0.00, 1.83, 2.29, 0.5, 0.99]\n","model_dir = base + '/UNetMulti'\n","lbl = '/Data/TestMultiLbl.tif'\n","labels = ['Water', 'Bare soil', 'Forest', 'Plantation']\n","\n","# # Sub\n","# Nclasses = 7\n","# train_base = base + '/sub_train'\n","# val_base = base + '/sub_val'\n","# Weight=[0.00, 1.22, 1.53, 1.65, 0.41, 0.79, 4.09]\n","# model_dir = base + '/UNetSub'\n","# lbl = '/Data/TestSubLbl.tif'\n","# labels = ['Water', 'Bare soil', 'Regrowth forest', 'Dense forest', 'Mature plantation', 'Young plantation']"],"metadata":{"id":"YwwvQ-ENp43g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create dataset"],"metadata":{"id":"nDE_tn0ZpMEe"}},{"cell_type":"code","metadata":{"id":"psz7wJKalaoj"},"source":["# Specify the size and shape of patches expected by the model\n","kernel_size = 128\n","features = ['Capella', 'Label', 'Mask']\n","\n","columns = [tf.io.FixedLenFeature(shape=[kernel_size, kernel_size], dtype=tf.float32) for k in features]\n","features_dict = dict(zip(features, columns))\n","\n","# Sizes of the training and evaluation datasets.\n","train_size= int(100*120*12 *0.33) #47520\n","val_size = int(100*90*2 *0.33)    #5940\n","\n","# Specify model training parameters\n","batch_size = 64\n","buffer_size = train_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Functions used to create dataset\n","\n","class Augment(tf.keras.layers.Layer):\n","  def __init__(self, seed=42):\n","    super().__init__()\n","    ang_list = [0, 0.25, 0.5, 0.75]\n","    rdm_ang = ang_list[random.randrange(len(ang_list))]\n","    self.augment = tf.keras.Sequential([\n","                      tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n","                      # tf.keras.layers.RandomRotation(factor=(0,1), fill_mode=\"reflect\"),\n","                      tf.keras.layers.RandomRotation(factor=(rdm_ang,rdm_ang), fill_mode=\"reflect\"),\n","                      ])\n","  def call(self, inputs, labels, masks):\n","    comb_tensor = tf.concat([inputs, labels, masks], axis=-1)\n","    augmented = self.augment(comb_tensor)\n","    inputs, labels, masks = tf.split(augmented, 3, axis=-1)\n","    return inputs, labels, masks\n","\n","def parse_tfrecord(example_proto):\n","    return tf.io.parse_single_example(example_proto, features_dict)\n","\n","# Disstack the data into image, label and mask\n","def to_tuple(inputs):\n","    inputsList = [inputs.get(key) for key in features]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","\n","    data = stacked[:,:,:1]\n","    label = stacked[:,:,1:2]\n","    # Convert nan to 0 in the label data\n","    label = tf.where(condition=tf.math.is_nan(label), x=tf.zeros_like(label), y=label)\n","    mask = stacked[:,:,2:3]\n","\n","    return data, label, mask\n","\n","def training_dataset():\n","    glob = train_base + '*'\n","    glob = tf.io.gfile.glob(glob)\n","    ds = tf.data.TFRecordDataset(glob, compression_type='GZIP').map(parse_tfrecord, num_parallel_calls=5)\n","    ds = ds.map(to_tuple, num_parallel_calls=5).map(Augment(), num_parallel_calls=5)\n","    ds = ds.shuffle(buffer_size).repeat().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","def eval_dataset():\n","    glob = val_base + '*'\n","    glob = tf.io.gfile.glob(glob)\n","    ds = tf.data.TFRecordDataset(glob, compression_type='GZIP').map(parse_tfrecord, num_parallel_calls=5)\n","    ds = ds.map(to_tuple, num_parallel_calls=5).repeat().batch(1).prefetch(tf.data.AUTOTUNE)\n","    return ds\n","\n","training = training_dataset()\n","evaluation = eval_dataset()"],"metadata":{"id":"yypB-4BBDgol"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWZ0UXCVMyJP"},"source":["# Print the 777th iteration training data and time to print it\n","start = datetime.datetime.now()\n","print(iter(training.take(777)).next())\n","finish = datetime.datetime.now()\n","print(finish-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the 99th iteration validation data and time to print it\n","start = datetime.datetime.now()\n","print(iter(evaluation.take(99)).next())\n","finish = datetime.datetime.now()\n","print(finish-start)"],"metadata":{"id":"pe8Tb1OLFCfx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build a model"],"metadata":{"id":"W8_JATRhsO-C"}},{"cell_type":"code","source":["# Modified functions from https://github.com/Asad-Ismail/lane_detection/blob/0e2ca0c6796634a4a1d1945828445580dc6507e0/scripts/losses.py\n","\n","def onehot(y_true, n_classes=Nclasses):\n","    #Squueeze if the tensor is already 4 dimneional\n","    if len(y_true.shape) == 4:\n","        y_true = tf.squeeze(y_true, -1)\n","    y_true = tf.one_hot(tf.cast(y_true, tf.int32), n_classes)\n","    y_true = tf.cast(y_true, tf.float32)\n","    return y_true\n","\n","def sparse_weighted_crossentropy(weights):\n","    weights=tf.constant(weights,dtype=tf.float32)\n","    def loss(y_true, y_pred):\n","        y_true = onehot(y_true)\n","        y_pred = softmax(y_pred)\n","        y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1-tf.keras.backend.epsilon())\n","        loss = weights * ( y_true * tf.math.log(y_pred) + (tf.ones_like(y_true)-y_true) * tf.math.log(tf.ones_like(y_true)-y_pred) )\n","        loss = -1 * tf.keras.backend.sum(loss, axis=-1)\n","        loss = tf.keras.backend.mean(loss)\n","        return loss\n","    return loss"],"metadata":{"id":"O-Wjfdv91Bfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define parameters and loss function for U-Net\n","LearningRate = 0.001\n","Epochs =50\n","\n","# Loss = tf.keras.losses.SparseCategoricalCrossentropy()\n","Loss = sparse_weighted_crossentropy(weights=Weight)\n","# Loss = SparseCategoricalFocalLoss(gamma=2, class_weight=Weight)"],"metadata":{"id":"pRJI1wQ9xLNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a model\n","\n","def conv_block(input_tensor, num_filters):\n","\tencoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n","\tencoder = tf.keras.layers.BatchNormalization()(encoder)\n","\tencoder = tf.keras.layers.Activation('relu')(encoder)\n","\tencoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n","\tencoder = tf.keras.layers.BatchNormalization()(encoder)\n","\tencoder = tf.keras.layers.Activation('relu')(encoder)\n","\treturn encoder\n","\n","def encoder_block(input_tensor, num_filters):\n","\tencoder = conv_block(input_tensor, num_filters)\n","\tencoder_pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n","\tencoder_pool = tf.keras.layers.Dropout(0.2)(encoder_pool)\n","\treturn encoder_pool, encoder\n","\n","def decoder_block(input_tensor, concat_tensor, num_filters):\n","\tdecoder = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n","\tdecoder = tf.keras.layers.concatenate([concat_tensor, decoder], axis=-1)\n","\tdecoder = tf.keras.layers.BatchNormalization()(decoder)\n","\tdecoder = tf.keras.layers.Activation('relu')(decoder)\n","\tdecoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","\tdecoder = tf.keras.layers.BatchNormalization()(decoder)\n","\tdecoder = tf.keras.layers.Activation('relu')(decoder)\n","\tdecoder = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n","\tdecoder = tf.keras.layers.BatchNormalization()(decoder)\n","\tdecoder = tf.keras.layers.Activation('relu')(decoder)\n","\treturn decoder\n","\n","\n","def get_unet():\n","\tfilter = 32\n","\tinputs = tf.keras.layers.Input(shape=(None,None,1)) # None\n","\tencoder0_pool, encoder0 = encoder_block(inputs, filter) # None/2\n","\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, filter*2) # None/4\n","\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, filter*4) # None/8\n","\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, filter*8) # None/16\n","\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, filter*16) # None/32\n","\tcenter = conv_block(encoder4_pool, filter*32) # center\n","\tdecoder4 = decoder_block(center, encoder4, filter*16) # None/16\n","\tdecoder3 = decoder_block(decoder4, encoder3, filter*8) # None/8\n","\tdecoder2 = decoder_block(decoder3, encoder2, filter*4) # None/4\n","\tdecoder1 = decoder_block(decoder2, encoder1, filter*2) # None/2\n","\tdecoder0 = decoder_block(decoder1, encoder0, filter) # None\n"," \t\n","\toutputs = tf.keras.layers.Conv2D(Nclasses, (1, 1), padding='same')(decoder0)\n","\n","\tmodel = tf.keras.models.Model(inputs=[inputs], outputs=[outputs])\n","\n","\tmodel.compile(\n","\t\toptimizer=tf.keras.optimizers.Adam(LearningRate), \n","\t\tloss=Loss,\n","\t\tmetrics=['accuracy'],\n","\t\trun_eagerly=True\n","\t\t)\n","\n","\treturn model"],"metadata":{"id":"3F0-ubhC7_Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = get_unet()\n","model.summary()"],"metadata":{"id":"xL3RxoRprzBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and validation"],"metadata":{"id":"D4xVVDlDsS0x"}},{"cell_type":"code","source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='unet_v2')\n","\n","model.fit(\n","    x=training, \n","    epochs=Epochs, \n","    steps_per_epoch=train_size // batch_size, \n","    validation_data=evaluation,\n","    validation_steps=val_size // 1 ,\n","\t\tcallbacks=[tensorboard_callback])"],"metadata":{"id":"v-KACCTa8Wdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the accuracy and loss throughout the epochs\n","%load_ext tensorboard\n","%tensorboard --logdir 'unet_v2'"],"metadata":{"id":"q5Vj-vj5CFEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a directry to save the trained model\n","# model_dir = '/UNetBin'\n","# model_dir = '/UNetMulti'\n","# model_dir = '/UNetSub'\n","# model_dir = '/weightedUNetBin'\n","# model_dir = '/weightedUNetMulti'\n","model_dir = '/weightedUNetSub'\n","\n","# Save the trained model\n","model.save(base + model_dir, save_format='tf')"],"metadata":{"id":"zfbHdvZfcPWP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","# model = tf.keras.models.load_model(base + model_dir)\n","model = tf.keras.models.load_model(base + model_dir, custom_objects={'loss': sparse_weighted_crossentropy(Weight)}) "],"metadata":{"id":"uBllxT78xdNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model evaluation\n","model.evaluate(evaluation,steps=val_size // 1,verbose=1)"],"metadata":{"id":"gBuydDMT-j0n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optional: visualize dataset for multi-class"],"metadata":{"id":"jBdLTKH3Ub9G"}},{"cell_type":"code","source":["from matplotlib.colors import ListedColormap, Normalize\n","import matplotlib.pyplot as plt\n","%pip install earthpy --quiet\n","import earthpy.plot as ep\n","\n","# Color map\n","class_colors_dict = {\n","    'Background':      [0.5, 0.5, 0.5, 1],  \n","    'Water':     [0,   0,   1,   1],   \n","    'Bare soil':     [1,   0,   1,   1],\n","    'Forest':     [0,   1,   0,   1],\n","    'Plantation':     [0.7,   1,   0.7,   1], \n","}\n","class_cm = np.array([v for k,v in class_colors_dict.items()])\n","class_map = class_cm[np.unique([0., 1., 2., 3., 4.]).astype(int)]\n","cmap = ListedColormap(class_map)"],"metadata":{"id":"PcehUw1YWQMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the image, mask, true label and predicted label\n","def display(display_list):\n","  title = ['Input Image', 'Mask', 'Label']\n","  fig, (ax_img, ax_msk, ax_tru) = plt.subplots(1, 3, figsize=(10, 10))\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    display_list[i] = np.squeeze(display_list[i])\n","    if i == 0:\n","      ax_img = plt.imshow(display_list[i], cmap='gray', vmin=0, vmax=0.1)\n","    if i == 1:\n","      ax_msk = plt.imshow(display_list[i], cmap=ListedColormap(['darkslategray', 'white']))\n","      # ep.draw_legend(ax_msk, titles=[\"background\", \"labels\"])\n","    if i == 2:\n","      ax_tru = plt.imshow(display_list[i], cmap=cmap)\n","      # ep.draw_legend(ax_tru, titles=list(class_colors_dict.keys()))\n","  plt.show()\n","  return\n","\n","for img, lbl, msk in training:\n","  display([np.squeeze(img), np.squeeze(msk), np.squeeze(lbl)])"],"metadata":{"id":"Jui8Q2z6UbKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Nclasses = 5\n","lbl = '/Data/TrainMultiLbl.tif'\n","Weight=[0.00, 1.83, 2.29, 0.5, 0.99]\n","model_dir = '/UNetMulti'\n","class_colors_dict = {\n","    'Background':      [0.5, 0.5, 0.5, 1],  \n","    'Water':     [0,   0,   1,   1],   \n","    'Bare soil':     [1,   0,   1,   1],\n","    'Forest':     [0,   1,   0,   1],\n","    'Plantation':     [0.7,   1,   0.7,   1], \n","}\n","results = '/Results/PredMultiUNet.tif'\n","\n","# Load image and make it readable as a numpy matrix\n","def open_raster(raster_path):\n","    with rasterio.open(raster_path, 'r') as ds:\n","        return ds.read() \n","\n","# Test data\n","image = open_raster(base + '/Data/TrainImg_spk.tif')\n","image[np.isnan(image)] = 0\n","\n","label = open_raster(base + lbl)\n","label[np.isnan(label)] = 0\n","label[label<0] =0\n","\n","mask = open_raster(base + '/Data/TrainMsk.tif')\n","mask[np.isnan(mask)] = 0\n","mask[mask<0] =0\n","\n","# 3D to 4D\n","image = np.expand_dims(image, -1)\n","image = np.squeeze(image)\n","label = np.expand_dims(label, -1)\n","label = np.squeeze(label)\n","mask = np.expand_dims(mask, -1)\n","mask = np.squeeze(mask)"],"metadata":{"id":"DafXsrAXIx8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the image, mask, true label and predicted label\n","def display(display_list):\n","  title = ['Input Image', 'Mask', 'True Label']\n","  fig, (ax_img, ax_msk, ax_tru) = plt.subplots(1, 3, figsize=(15, 15))\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    display_list[i] = np.squeeze(display_list[i])\n","    if i == 0:\n","      ax_img = plt.imshow(display_list[i], cmap='gray', vmin=0, vmax=0.6)\n","    if i == 1:\n","      ax_msk = plt.imshow(display_list[i], cmap=ListedColormap(['darkslategray', 'white']))\n","      # ep.draw_legend(ax_msk, titles=[\"background\", \"labels\"])\n","    if i == 2:\n","      ax_tru = plt.imshow(display_list[i], cmap=cmap)\n","      ep.draw_legend(ax_tru, titles=list(class_colors_dict.keys()))\n","  plt.show()\n","  return\n","\n","def create_mask(pred_mask):\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask[0]\n","\n","def predictions(img, msk, lbl):\n","    return display([img, msk, lbl])\n","\n","predictions(image, mask, label)"],"metadata":{"id":"kIRUup9CJJxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  image = image[256:(256+128), 128*i:128*(i+1)]\n","  mask = mask[256:(256+128), 128*i:128*(i+1)]\n","  label = label[256:(256+128), 128*i:128*(i+1)]\n","  predictions(image, mask, label)"],"metadata":{"id":"lp0MrTFnJtut"},"execution_count":null,"outputs":[]}]}